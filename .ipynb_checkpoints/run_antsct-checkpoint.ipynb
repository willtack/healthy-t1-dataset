{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run ANTs-CT analyses for T1 Normative Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import flywheel\n",
    "fw = flywheel.Client()\n",
    "collection_id = '5eb5081448fe1b1e5792a7a9'\n",
    "gear = fw.lookup('gears/antsct-aging-fw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "# Here we get all the sessions within the collection.\n",
    "# We use `get_session` to return the associated analyses\n",
    "sessions = [fw.get_session(x.id) for x in fw.get_collection_sessions(collection_id)]\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### For each session, select appropriate acquisition and run gear on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_t1s = []\n",
    "no_t1_sessions = []\n",
    "analysis_ids = []\n",
    "sessions_short = [fw.get('5e5801b06dea3101ae2a7457'), fw.get('5e5803f86dea31029a2a7452')]\n",
    "sessions_short2 = []\n",
    "\n",
    "for session in sessions_short:\n",
    "    ## Get acquisition\n",
    "    potential_t1s = []\n",
    "    for acq in session.acquisitions():\n",
    "        class_t1 = False\n",
    "        class_struct_intent = False\n",
    "        class_mprage = False\n",
    "        if acq.files and len(acq.files) > 0:\n",
    "            for i in range(0, len(acq.files)):\n",
    "                try: \n",
    "                    class_t1 = 'T1' in acq.files[i]['classification']['Measurement'] \n",
    "                    class_struct_intent = 'Structural' in acq.files[i]['classification']['Intent']\n",
    "                    class_mprage = 'MPRAGE' in acq.files[i]['classification']['Features']\n",
    "                except TypeError as te:\n",
    "                    continue\n",
    "                except KeyError as ke:\n",
    "                    continue                \n",
    "                break                    \n",
    "\n",
    "        # follow a hierarchy of surest identifiers of the desired T1 acquisition (usually mprage, never setter, etc.)\n",
    "        is_mprage = class_mprage or \"mprage\" in acq.label.lower() or 't1w_mpr' in acq.label.lower()                           \n",
    "        if is_mprage and \"setter\" not in acq.label:\n",
    "            potential_t1s.insert(0, acq)\n",
    "        elif class_t1 and class_struct_intent and \"setter\" not in acq.label:\n",
    "            potential_t1s.append(acq)\n",
    "        else:\n",
    "            pass\n",
    "            \n",
    "    if len(potential_t1s) == 0:\n",
    "        sub = fw.get(session.parents['subject'])\n",
    "        no_t1_sessions.append('{}: {}'.format(sub.label, session.label))\n",
    "    else:\n",
    "        # add the highest priority acquisition to the input T1s list\n",
    "        input_t1_acq = potential_t1s[0]\n",
    "        input_t1s.append(input_t1_acq)\n",
    "    \n",
    "    for f in input_t1_acq.files:\n",
    "        if 'nii.gz' in f.name:\n",
    "            input_file = f\n",
    "            break\n",
    "\n",
    "    # Run the gear\n",
    "    inputs = {'t1_anatomy': input_file}\n",
    "    config = {'denoise': True, 'num-threads': 0, 'trim-neck': True, 'run-quick': True}\n",
    "    analysis_id = gear.run(analysis_label='antsct_2020-12-08_WT quick test', config=config, inputs=inputs, destination=session)\n",
    "    analysis_ids.append(analysis_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C01_20150107\n",
      "C18_20160223\n"
     ]
    }
   ],
   "source": [
    "print(sessions_short[0].label)\n",
    "print(sessions_short[1].label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fw.download_tar(input_t1s, '/home/will/Desktop/normative_dataset.tar')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sanity check the length and contents of the list of T1 acquisitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(len(input_t1s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(no_t1_sessions))\n",
    "no_t1_sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t1 in input_t1s:\n",
    "    sub = fw.get(t1.parents['subject'])\n",
    "    ses = fw.get(t1.parents['session'])\n",
    "    print('{} | {} | {}'.format(t1.label, sub.label, ses.label))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
